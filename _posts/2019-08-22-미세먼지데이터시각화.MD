---
title: 미세먼지 데이터 시각화
author: loveAlakazam
categories: [프로젝트2019]
tags: [Pandas, Seaborn, Python3, Jupyter Notebook]
comments: false
---

> # 1. 소개 & 활용 기술 스택

<br>

> ## 소개

- 1987년부터 2019년 까지의 미세먼지양과 초미세먼지양을 그래프로 시각화
  - 히트맵 그래프
  - Barplot(막대그래프)
  - 상관관계 그래프

<br>

> ## 활용 기술 스택

- #### Language: `Python3`,
- #### Library : `pandas`, `seaborn`, `matplotlib`

<br>

> # 2. 구현과정

<br>

- ### 공공데이터 포털에서 데이터를 수집

- ### pandas를 활용한 데이터 가공

- ### seaborn을 활용한 데이터 시각화

<br><br>

> # 3. 시각화 결과 & 배운점

<BR>

> ## 데이터 시각화 결과

- #### 1. 히트맵 그래프

![](/assets/img/blog_imgs/2019_dustv/d1.png)

<BR>

- #### 2. 히트맵 그래프 2

![](/assets/img/blog_imgs/2019_dustv/d2.png)

<BR>

- #### 3. 상관관계 그래프

![](/assets/img/blog_imgs/2019_dustv/d3.png)

<BR>

- #### 4. 년도별 미세먼지 농도 막대그래프

![](/assets/img/blog_imgs/2019_dustv/d4.png)

<BR>

- #### 5. 년도별 초미세먼지 농도 막대그래프

![](/assets/img/blog_imgs/2019_dustv/d5.png)

<br><br>

> ## 소스코드

- [깃허브 소스코드]https://github.com/loveAlakazam/kaggle_toddler/blob/master/dinosaur_study/Dust_Visualization/dust_visualization_by_seaborn.ipynb)

- 아래 소스코드는 jupyter notebook에서 _.ipynb를 _.py로 변환시켰습니다.

```python
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np


# # 1. 데이터 수집 및 합치기

# ## (data1) 1987년 1월 ~ 2017년 12월 데이터
#
# 그런데 아래 파일은 1987년 1월 ~ 2019년 5월 까지로 되어있습니다.
#
# 즉, 원하는 데이터는 1987년 1월 ~ 2017년 12월 까지입니다.
#
# 2018년~2019년 데이터를 제거합니다.

# In[39]:


dust_data1=pd.read_csv('./dust_data201910/dust_data_inSeoul_19870101_201905.csv', encoding='utf-8')
dust_data1.head(3)


#
# 1987년 1월1일 ~ 2017년 12월 31일 데이터로 갱신하면 됩니다.

# In[3]:


# dust_data1['측정월'] 데이터타입
type(dust_data1.loc[0,'측정월'])


# In[40]:


dust_data1=dust_data1[ dust_data1['측정월']<201900]
dust_data1.reset_index(inplace=True, drop=True)
dust_data1.head(3)


# In[41]:


dust_data1.shape


# ### 컬럼 추가 / 컬럼 제거 / 컬럼 이름 변경
#
# 1. 년/ 월 컬럼 추가
# 2. 측정월 컬럼 제거
# 3. 컬럼명 변경
#     - 측정소명 ->구
#     - 이산화질소농도(ppm) -> 이산화질소(ppm)
#     - 오존농도(ppm) -> 오존(ppm)
#     - 일산화탄소농도(ppm) -> 일산화탄소(ppm)
#     - 나머지(미세먼지/초미세먼지/ 아황산가스) 동일

# In[42]:


# 년/월 컬럼 추가
dust_data1['년']=dust_data1['측정월']//100
dust_data1['월']=dust_data1['측정월']%100

# 측정월 컬럼 삭제
dust_data1=dust_data1.drop('측정월',1) #열삭제 1

# dust_data1의 컬럼
dust_data1_cols=dust_data1.columns

# 컬럼명 변경
dust_data1.rename(
    columns={
        dust_data1_cols[0]:'구',
        dust_data1_cols[1]:'이산화질소',
        dust_data1_cols[2]:'오존',
        dust_data1_cols[3]:'일산화탄소',
        dust_data1_cols[4]:'아황산가스',
        dust_data1_cols[5]:'미세먼지',
        dust_data1_cols[6]:'초미세먼지'}, inplace=True)

dust_data1.head(3)


# In[43]:


dust_data1['구'].value_counts()


# <br>
#
# ## (data2) 2018년 1월 ~ 2019년 10월 데이터 수집
#
# 그러나 data2는 data1과 다르게 '권역명'이라는 컬럼이 하나 더있습니다.
#
# data1과 달리 1일마다 측정한 결과라서, 월별로 측정한 결과로 나타내야합니다.
#
# 컬럼을 같게해야 합칠 수있기 때문에 공통컬럼이 아닌 컬럼은 제거합니다.

# In[68]:


dust_data2=pd.read_csv('./dust_data201910/dust_data_inSeoul_20180101_20191031.csv', encoding='utf-8')
dust_data2.head(3)


# In[45]:


dust_data2['측정소명'].value_counts()


# In[64]:


dust_data2['측정소명'].value_counts().keys()


# In[8]:


dust_data2.shape


# ### 컬럼 추가/ 컬럼 제거 / 컬럼 이름 변경
#
# 1. 권역명 컬럼 제거
# 2. 측정일자 -> 년/ 월 컬럼 추가
# 3. 측정일자 컬럼 제거
# 4. 컬럼 이름 변경
#     - 측정소명 -> 구
#     - 이산화질소농도(ppm) -> 이산화질소(ppm)
#     - 일산화탄소농도(ppm) -> 일산화탄소(ppm)
#     - 아황산가스농도(ppm) -> 아황산가스(ppm)

# In[46]:


# 권역명 컬럼 삭제
dust_data2=dust_data2.drop('권역명', 1) #열삭제 1

# 년/월 컬럼 추가
dust_data2['년']=dust_data2['측정일자']//10000
dust_data2['월']=dust_data2['측정일자']%10000//100
dust_data2['일']=dust_data2['측정일자']%10000%100

# 측정일자 컬럼 삭제
dust_data2=dust_data2.drop('측정일자',1) #열삭제 1


# In[47]:


dust_data2


# In[49]:


cities=dust_data2['측정소명'].value_counts().keys()
months=list(range(1,13))
for cities=

dust_data2.loc[ (dust_data2['측정소명']=='중구') & (dust_data2['월']==10) ]


dust_data2_cols= dust_data2.columns
# 컬럼명 변경
dust_data2.rename(
    columns={
        dust_data2_cols[0]:'구',
        dust_data2_cols[1]:'미세먼지',
        dust_data2_cols[2]:'초미세먼지',
        dust_data2_cols[3]:'오존',
        dust_data2_cols[4]:'이산화질소',
        dust_data2_cols[5]:'일산화탄소',
        dust_data2_cols[6]:'아황산가스'}, inplace=True)

dust_data2.head(3)


# ### 컬럼명/ 컬럼개수 / 컬럼순서를  동일하게 만듭니다.
#
# - 합친 데이터 프레임의 구성컬럼
#     - 년
#     - 월
#     - 구
#     - 미세먼지(㎍/㎥)
#     - 초미세먼지(㎍/㎥)
#     - 이산화질소(ppm)
#     - 오존(ppm)
#     - 일산화탄소(ppm)
#     - 아황산가스(ppm)

# In[10]:

# 공통 컬럼정의
common_cols=['년','월', '구', '미세먼지', '초미세먼지',
             '이산화질소', '오존', '일산화탄소', '아황산가스']

dust_data1= dust_data1.loc[:, common_cols]
dust_data2= dust_data2.loc[:, common_cols]


# In[11]:


dust_data1.head(3)


# In[12]:


dust_data2.head(3)


#
#
# ##  (data1 + data2) 데이터 합치기
#
# 위에서 컬럼의 개수를 동일하게 설정했고, 목적에맞는 데이터를 수집했다면
#
# 합치기 전에 두 데이터의 컬럼명을 동일하게 해야합니다.

# In[13]:


# 가장 최신의 데이터가 맨위에 위치하도록 합니다.
dust_df= pd.concat([dust_data2, dust_data1], ignore_index=True)
dust_df.head(3)
print(dust_df.shape)


# <br>
#
# ------------------------------------------
#
# # 데이터 가공

# ## (1) NaN값 처리

# In[14]:


# 각 컬럼별 NaN값을 확인해야합니다.
dust_cols=dust_df.columns.tolist()
dust_cols


# In[15]:


# NaN개수를 카운트
for dcol in dust_cols:
    print('컬럼 "{0}"의 NaN개수: {1}'.format(dcol, dust_df[dcol].isnull().sum()))


# <br>
# 위의 결과 NaN가 존재하는 컬럼은 년/월/구 를 제외한 나머지 컬럼입니다.
#
# NaN이 존재하는 컬럼들은 측정값이기 때문에
#
# 존재하지 않는다면 0으로 합니다.

# In[31]:


# fillna() 함수를 이용해서 -> NaN값을 0으로 바꿉니다.
dust_df.fillna(0)
dust_df['년'].value_counts()


# In[17]:


# 통합시킨 데이터를 저장합니다.
dust_df.to_csv('./dust_data201910/dust_data198701_201910.csv', encoding='utf-8')


# # [데이터 시각화 1] Heat Map 그래프
#
# # 년도별 미세먼지, 초미세먼지 측정
#
# * 진행기간: 8월23일 ~ 8월27일
# <br>
#
# 년(year)을 기준으로 pivot테이블을 만듭니다.

# In[29]:


visual_dust_tb1 = pd.pivot_table( dust_df, index='년', aggfunc=np.sum)
visual_dust_tb1.head()


# In[19]:


visual_dust_tb1=visual_dust_tb1.drop('월',1) #월 컬럼 지운다.
visual_dust_tb1.head(3)


# Seaborn 특성상 영어폰트 외의 다른 폰트 지원을 받지 않으므로
#
# 영어로 나타내보겠습니다.

# In[20]:


# # visual_dust_tb1.index이름 변경
# visual_dust_tb1.rename(index={'년':'Year'}, inplace=True)

# # visual_dust_tb1.columns 컬럼 이름변경
# visual_dust_tb1.columns=['PM-10', 'S02', 'O3', 'NO2', 'CO', 'PM-2.5']
# visual_dust_tb1.head(3)


# In[21]:


import matplotlib.pyplot as plt
import seaborn as sns
get_ipython().run_line_magic('matplotlib', 'inline')

import warnings
warnings.filterwarnings('ignore')

import platform
from matplotlib import font_manager, rc

path='C:/Windows/Fonts/malgun.ttf'
if platform.system()=='Windows':
    font_name= font_manager.FontProperties(fname=path,size=10).get_name()
    rc('font', family=font_name)


# In[22]:


# Seaborn은 한글데이터가 시각화가 안되서 영어로 나타냈습니다.
# 컬럼이름 변경
visual_dust_tb1.columns= ['PM-10', 'SO2', 'O3', 'NO2', 'CO', 'PM-2.5']

# 인덱스 이름 변경 (년-> Year)
visual_dust_tb1.index.name='Year'


# In[23]:


# 히트맵 시각화할때 보여주고 싶은 컬럼(미세먼지, 초미세먼지)
target_cols_order=['PM-10', 'PM-2.5']

plt.figure(figsize=(10,9))

sns.heatmap(
    data=visual_dust_tb1[target_cols_order], annot=True, fmt='.1f',
    linewidths=.1, robust=True)
plt.title('1987년 ~ 2019년 서울특별시 대기오염 히트맵 그래프1')
plt.show()


# In[24]:


# 히트맵 시각화할때 보여주고 싶은 컬럼(아황산가스, 이산화질소, 일산화탄소)
target_cols_order=['SO2', 'O3', 'NO2', 'CO']

plt.figure(figsize=(8,10))

sns.heatmap(
    data=visual_dust_tb1[target_cols_order], annot=True, fmt='.1f',
    linewidths=.1,linecolor='black', robust=True, cmap='YlGnBu')
plt.title('1987년 ~ 2019년 서울특별시 대기오염 히트맵 그래프2')
plt.show()


# # [데이터 시각화2] 상관관계 그래프 (PairPlot)
#
# - PM-2.5와 PM-10 은 비례할까?
# - PM-10과 가스(O3, CO, NO2, SO2)는 어떤관계를 가질까?
# - PM-2.5와 가스(O3, CO, NO2, SO2)

# In[25]:


sns.pairplot(
    visual_dust_tb1,
    x_vars=['PM-10','PM-2.5' ],
    y_vars=['CO', 'O3', 'SO2'],
    kind='reg',
    height=5)


# In[26]:


sns.set(style='whitegrid')
plt.figure(figsize=(16,8))

sns.barplot(x=visual_dust_tb1.index, y='PM-10', data=visual_dust_tb1)
plt.title('연도별 서울특별시 미세먼지량(PM-10) 그래프')
plt.show()


# In[27]:


sns.set(style='whitegrid')
plt.figure(figsize=(16,8))

sns.barplot(x=visual_dust_tb1.index, y='PM-2.5', data=visual_dust_tb1)
plt.title('연도별 서울특별시 초미세먼지량(PM-2.5) 그래프')
plt.show()

```

<br><br>

- ### 배운점

- pandas와 seaborn은 처음 접해봤다.
- 2019년 네이버 썸머해커톤에서 미세먼지 시각화가 있길래 지원은 했으나 떨어져서 아쉬운 마음에, 그래도 해보고 싶은거 스스로 찾아서 해봤다.
- 데이터 가공이 쉽지 않았다.
  - 어떤 함수를 써야될지 몰라서 다큐먼트나 오픈소스를 많이 활용했다.
  - `파이썬 라이브러리를 활용한 데이터 분석`, `파이썬으로 데이터 주무르기` 의 예제를 참고하여 pandas와 데이터 시각화를 익혔다.
- 그래도 내가 찾아보면서 직접 배우고 적용하는 과정에서 시간이 가는줄 모르고 재밌게했다.

<br><br><br>

> # 4. 보완점

<br>

- 다양한 디자인의 그래프 시각화
  - D3.js
  - 정적인 그래프가 아닌 동적인 그래프로 미세먼지 농도를 데이터 시각화
- 서울뿐만 아니라 다른 지역의 미세먼지 농도를 데이터 시각화
- seaborn에서 한글인코딩이 어려워서 글자가 깨졌다.

<br><br><br>

> # 5. 결과물/시연영상

[미세먼지 데이터 시각화 블로그 포스팅](https://blog.naver.com/rose1216_/221625072157)

<b></b>
